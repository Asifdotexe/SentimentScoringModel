{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, TreebankWordTokenizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "\n",
    "from src.nlp_preprocessing import pos_tag\n",
    "from src.nlp_preprocessing import penn_to_wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/preprocessed_small_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(text):\n",
    "    \n",
    "    \"\"\"\n",
    "        This method returns the sentiment score of a given text using SentiWordNet sentiment scores.\n",
    "        input: text\n",
    "        output: numeric (double) score, >0 means positive sentiment and <0 means negative sentiment.\n",
    "    \"\"\"    \n",
    "    total_score = 0\n",
    "    #print(text)\n",
    "    raw_sentences = sent_tokenize(text)\n",
    "    #print(raw_sentences)\n",
    "    \n",
    "    for sentence in raw_sentences:\n",
    "\n",
    "        sent_score = 0     \n",
    "        sentence = str(sentence)\n",
    "        #print(sentence)\n",
    "        sentence = sentence.replace(\"<br />\",\" \").translate(str.maketrans('','',punctuation)).lower()\n",
    "        tokens = TreebankWordTokenizer().tokenize(text)\n",
    "        tags = pos_tag(tokens)\n",
    "        for word, tag in tags:\n",
    "            wn_tag = penn_to_wn(tag)\n",
    "            if not wn_tag:\n",
    "                continue\n",
    "            lemma = WordNetLemmatizer().lemmatize(word, pos=wn_tag)\n",
    "            if not lemma:\n",
    "                continue\n",
    "            synsets = wn.synsets(lemma, pos=wn_tag)\n",
    "            if not synsets:\n",
    "                continue\n",
    "            synset = synsets[0]\n",
    "            swn_synset = swn.senti_synset(synset.name())\n",
    "            sent_score += swn_synset.pos_score() - swn_synset.neg_score()\n",
    "\n",
    "        total_score = total_score + (sent_score / len(tokens))\n",
    "\n",
    "    \n",
    "    return (total_score / len(raw_sentences)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "swn.senti_synset(wn.synsets(\"amazing\", wn.ADJ)[0].name()).pos_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS score: 0.0\n",
      "NEG score: 0.375\n",
      "POS OBJ: 0.625\n",
      "Overall Score: -0.375\n",
      "\n",
      "POS score: 0.125\n",
      "NEG score: 0.375\n",
      "POS OBJ: 0.5\n",
      "Overall Score: -0.25\n",
      "\n",
      "POS score: 0.0\n",
      "NEG score: 0.125\n",
      "POS OBJ: 0.875\n",
      "Overall Score: -0.125\n",
      "\n",
      "POS score: 0.0\n",
      "NEG score: 0.125\n",
      "POS OBJ: 0.875\n",
      "Overall Score: -0.125\n",
      "\n",
      "POS score: 0.0\n",
      "NEG score: 0.0\n",
      "POS OBJ: 1.0\n",
      "Overall Score: 0.0\n",
      "\n",
      "POS score: 0.0\n",
      "NEG score: 0.125\n",
      "POS OBJ: 0.875\n",
      "Overall Score: -0.125\n",
      "\n",
      "POS score: 0.0\n",
      "NEG score: 0.375\n",
      "POS OBJ: 0.625\n",
      "Overall Score: -0.375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "synsets = swn.senti_synsets('abandon')\n",
    "\n",
    "for i in synsets:\n",
    "    print(\"POS score:\", i.pos_score())\n",
    "    print(\"NEG score:\", i.neg_score())\n",
    "    print(\"POS OBJ:\", i.obj_score())\n",
    "    print('Overall Score:', i.pos_score() - i.neg_score())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS score: 0.625\n",
      "NEG score: 0.0\n",
      "POS OBJ: 0.375\n",
      "Overall Score: 0.625\n",
      "\n",
      "POS score: 0.375\n",
      "NEG score: 0.0\n",
      "POS OBJ: 0.625\n",
      "Overall Score: 0.375\n",
      "\n",
      "POS score: 0.125\n",
      "NEG score: 0.0\n",
      "POS OBJ: 0.875\n",
      "Overall Score: 0.125\n",
      "\n",
      "POS score: 0.25\n",
      "NEG score: 0.0\n",
      "POS OBJ: 0.75\n",
      "Overall Score: 0.25\n",
      "\n",
      "POS score: 0.0\n",
      "NEG score: 0.0\n",
      "POS OBJ: 1.0\n",
      "Overall Score: 0.0\n",
      "\n",
      "POS score: 0.0\n",
      "NEG score: 0.0\n",
      "POS OBJ: 1.0\n",
      "Overall Score: 0.0\n",
      "\n",
      "POS score: 0.5\n",
      "NEG score: 0.0\n",
      "POS OBJ: 0.5\n",
      "Overall Score: 0.5\n",
      "\n",
      "POS score: 1.0\n",
      "NEG score: 0.0\n",
      "POS OBJ: 0.0\n",
      "Overall Score: 1.0\n",
      "\n",
      "POS score: 0.625\n",
      "NEG score: 0.0\n",
      "POS OBJ: 0.375\n",
      "Overall Score: 0.625\n",
      "\n",
      "POS score: 0.375\n",
      "NEG score: 0.125\n",
      "POS OBJ: 0.5\n",
      "Overall Score: 0.25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "synsets = swn.senti_synsets('love')\n",
    "\n",
    "for i in synsets:\n",
    "    print(\"POS score:\", i.pos_score())\n",
    "    print(\"NEG score:\", i.neg_score())\n",
    "    print(\"POS OBJ:\", i.obj_score())\n",
    "    print('Overall Score:', i.pos_score() - i.neg_score())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Before dropping nulls:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(9000, 16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'After dropping nulls:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8998, 16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display('Before dropping nulls:',df.shape)\n",
    "df = df.dropna(subset=['cleaned_review'])\n",
    "display('After dropping nulls:',df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_score'] = df['cleaned_review'].apply(lambda text : get_sentiment_score(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3086</th>\n",
       "      <td>this card wouldve been cute in a silly kind of way if the soundmusic was recognizable maybe i just got a defective card but its not the song thats played in the sample in the description  its not really a song or music at all just unrecognizable noise</td>\n",
       "      <td>['card', 'wouldve', 'be', 'cute', 'silly', 'kind', 'way', 'soundmusic', 'be', 'recognizable', 'maybe', 'i', 'just', 'get', 'defective', 'card', 'not', 'song', 'thats', 'played', 'sample', 'description', 'not', 'really', 'song', 'music', 'just', 'unrecognizable', 'noise']</td>\n",
       "      <td>0.520833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6695</th>\n",
       "      <td>love it</td>\n",
       "      <td>['love']</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>i ordered this scale before and the first one didnt work at all amazon sent a replacement and this one lasted a couple months and it started giving wild weight readings now it only reads error fitbit does not respond to emails regarding this dont waste your money on this scale</td>\n",
       "      <td>['i', 'order', 'scale', 'first', 'didnt', 'work', 'amazon', 'sent', 'replacement', 'last', 'couple', 'month', 'start', 'give', 'wild', 'weight', 'reading', 'now', 'only', 'read', 'error', 'fitbit', 'do', 'not', 'respond', 'email', 'regard', 'dont', 'waste', 'money', 'scale']</td>\n",
       "      <td>-1.715686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6317</th>\n",
       "      <td>its exactly what i have been looking for cover is made of good quality plastic love it</td>\n",
       "      <td>['exactly', 'i', 'have', 'be', 'look', 'cover', 'be', 'make', 'good', 'quality', 'plastic', 'love']</td>\n",
       "      <td>10.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>super thin bubbles pop really easily our breakage rate in shipping went way up using this bubble wrap went back to using blue hawk bubble wrap from lowes much tougher and tears far easier</td>\n",
       "      <td>['super', 'thin', 'bubble', 'pop', 'really', 'easily', 'breakage', 'rate', 'shipping', 'go', 'way', 'up', 'use', 'bubble', 'wrap', 'go', 'back', 'use', 'blue', 'hawk', 'bubble', 'wrap', 'lowes', 'much', 'tougher', 'tear', 'far', 'easy']</td>\n",
       "      <td>0.735294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                             cleaned_review  \\\n",
       "3086                            this card wouldve been cute in a silly kind of way if the soundmusic was recognizable maybe i just got a defective card but its not the song thats played in the sample in the description  its not really a song or music at all just unrecognizable noise   \n",
       "6695                                                                                                                                                                                                                                                                                love it   \n",
       "980   i ordered this scale before and the first one didnt work at all amazon sent a replacement and this one lasted a couple months and it started giving wild weight readings now it only reads error fitbit does not respond to emails regarding this dont waste your money on this scale   \n",
       "6317                                                                                                                                                                                                 its exactly what i have been looking for cover is made of good quality plastic love it   \n",
       "5                                                                                               super thin bubbles pop really easily our breakage rate in shipping went way up using this bubble wrap went back to using blue hawk bubble wrap from lowes much tougher and tears far easier   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                   lemmas  \\\n",
       "3086      ['card', 'wouldve', 'be', 'cute', 'silly', 'kind', 'way', 'soundmusic', 'be', 'recognizable', 'maybe', 'i', 'just', 'get', 'defective', 'card', 'not', 'song', 'thats', 'played', 'sample', 'description', 'not', 'really', 'song', 'music', 'just', 'unrecognizable', 'noise']   \n",
       "6695                                                                                                                                                                                                                                                                             ['love']   \n",
       "980   ['i', 'order', 'scale', 'first', 'didnt', 'work', 'amazon', 'sent', 'replacement', 'last', 'couple', 'month', 'start', 'give', 'wild', 'weight', 'reading', 'now', 'only', 'read', 'error', 'fitbit', 'do', 'not', 'respond', 'email', 'regard', 'dont', 'waste', 'money', 'scale']   \n",
       "6317                                                                                                                                                                                  ['exactly', 'i', 'have', 'be', 'look', 'cover', 'be', 'make', 'good', 'quality', 'plastic', 'love']   \n",
       "5                                            ['super', 'thin', 'bubble', 'pop', 'really', 'easily', 'breakage', 'rate', 'shipping', 'go', 'way', 'up', 'use', 'bubble', 'wrap', 'go', 'back', 'use', 'blue', 'hawk', 'bubble', 'wrap', 'lowes', 'much', 'tougher', 'tear', 'far', 'easy']   \n",
       "\n",
       "      sentiment_score  \n",
       "3086         0.520833  \n",
       "6695        25.000000  \n",
       "980         -1.715686  \n",
       "6317        10.294118  \n",
       "5            0.735294  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['cleaned_review','lemmas','sentiment_score']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

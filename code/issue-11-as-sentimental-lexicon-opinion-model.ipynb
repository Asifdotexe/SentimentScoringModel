{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opinion lexicon score model (Notebook 5/6)\n",
    "> Opinion Lexion: An opinion lexicon is a collection of words and phrases that are annotated with sentiment information, typically indicating whether each term carries a positive, negative, or neutral connotation. \n",
    "\n",
    "In this notebook, \n",
    "\n",
    "- I have made use of Opinion lexicon for creating the sentiment scoring model\n",
    "- We first breaks down the input text into sentences using the `sent_tokenize` function from nltk. \n",
    "- For each sentence, it calculates a sentence score by iterating over each token (word) in the sentence. \n",
    "- If the token is in the list of positive words from the opinion lexicon, the sentence score is incremented by 1. \n",
    "- If the token is in the list of negative words, the sentence score is decremented by 1. \n",
    "- Finally, the function returns the total sentiment score by summing up the sentence scores and dividing by the total number of tokens in all sentences.\n",
    "\n",
    "Next Notebook: `issue-13-as-analysis-on-opinion-lexicon-scores.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.tokenize import sent_tokenize, TreebankWordTokenizer\n",
    "from string import punctuation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# run if faced with an error\n",
    "# nltk.download('opinion_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: issue-5-as-data-preprocessing.ipynb\n",
    "df = pd.read_csv('../data/preprocessed_small_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the positive and negative words\n",
    "positive_words = list(opinion_lexicon.positive())\n",
    "negative_words = list(opinion_lexicon.negative())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opinion_lexicion_sentiment_score(text: str) -> float:\n",
    "    \"\"\"\n",
    "    This function calculates the sentiment score of a given text using the opinion lexicon provided by the Natural Language Toolkit (nltk).\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The input text for which the sentiment score needs to be calculated.\n",
    "\n",
    "    Returns:\n",
    "    - float: The sentiment score of the input text, where a higher score indicates a more positive sentiment and a lower score indicates a more negative sentiment.\n",
    "\n",
    "    Description\n",
    "    The function first breaks down the input text into sentences using the `sent_tokenize` function from nltk. Then, for each sentence, it calculates a sentence score by iterating over each token (word) in the sentence. If the token is in the list of positive words from the opinion lexicon, the sentence score is incremented by 1. If the token is in the list of negative words, the sentence score is decremented by 1. Finally, the function returns the total sentiment score by summing up the sentence scores and dividing by the total number of tokens in all sentences.\n",
    "    \"\"\"\n",
    "    \n",
    "    total_score = 0\n",
    "    raw_sentences = sent_tokenize(text)\n",
    "\n",
    "    for sentence in raw_sentences:\n",
    "        sentence_score = 0\n",
    "        sentence = str(sentence)\n",
    "        sentence = sentence.replace('<br/>', '')\\\n",
    "                            .translate(str.maketrans('', '', punctuation)).lower()\n",
    "        tokens = TreebankWordTokenizer().tokenize(text)\n",
    "\n",
    "        for token in tokens:\n",
    "            sentence_score = sentence_score + 1 if token in positive_words else (sentence_score - 1 if token in negative_words else sentence_score)\n",
    "        total_score = total_score + (sentence_score / len(tokens))\n",
    "\n",
    "    return total_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9000 entries, 0 to 8999\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   overall         9000 non-null   float64\n",
      " 1   verified        9000 non-null   bool   \n",
      " 2   reviewTime      9000 non-null   object \n",
      " 3   reviewerID      9000 non-null   object \n",
      " 4   asin            9000 non-null   object \n",
      " 5   style           5414 non-null   object \n",
      " 6   reviewerName    8995 non-null   object \n",
      " 7   reviewText      8999 non-null   object \n",
      " 8   summary         9000 non-null   object \n",
      " 9   unixReviewTime  9000 non-null   int64  \n",
      " 10  vote            1713 non-null   float64\n",
      " 11  image           188 non-null    object \n",
      " 12  cleaned_review  8998 non-null   object \n",
      " 13  tokens          9000 non-null   object \n",
      " 14  stemmed_tokens  9000 non-null   object \n",
      " 15  lemmas          9000 non-null   object \n",
      "dtypes: bool(1), float64(2), int64(1), object(12)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all values to strings, filling NaNs with empty strings\n",
    "df['cleaned_review'] = df['cleaned_review'].astype(str)\n",
    "df['sentiment_score'] = df['cleaned_review'].apply(lambda x: get_opinion_lexicion_sentiment_score(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7364</th>\n",
       "      <td>these are great</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cleaned_review  sentiment_score\n",
       "7364  these are great         0.333333"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['cleaned_review', 'sentiment_score']].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/opinion_lexicon_scored_small_sample.csv', index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
